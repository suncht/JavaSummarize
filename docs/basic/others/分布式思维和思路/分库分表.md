一. 分库分表
1. 优化时机
一般单表超过500万左右，或明显感觉到性能下降时，需要优化
> **题外话**：
（1）mysql单表达到1000W到2000W的时候还能提供较好的服务，目前线上有一张表1000W多点，还没有出现性能问题，多张表在几百万的数据，开始考虑分表了，如果表比较简单，索引合理的话300W完全不需要分表，记得DBA说过mysql单表超过5千万性能会下降的比较厉害，所以没达到千万级别还不需要考虑分表的事
（2）理论上确实5000万以上才会性能急剧下降，有些db架构师也是这么说过。但是实际情况却不一定，按照一部分的真实项目，500万以上就会开始慢了。当然，这个跟具体的业务逻辑、响应要求、表设计也是很有关系的。表字段全是int类型的，可以到1000万以上再优化。

2. 优化方案
+ 读写分离
+ 使用缓存，如memcached或Redis
+ 使用搜索引擎，如ElasticSearch或solr
+ 分库分表

> 题外话
（1）读写分离很容易实现，建议在一开始做，不必等到性能下降时
（2）使用缓存，发现性能下降时可做。比如有一张500万大表，不可能缓存全表，只能缓存热点数据，所以需要有一个监控热点数据的功能
（3）像缓存整个大表或者数据量很大可以用搜索引擎，搜索引擎是文件存储，适合高效查找，但不对插入修改、事务等支持。使用搜索引擎的话需要定时把mysql的数据同步给它，同样的数据需要预留2倍磁盘，虽然搜索引擎可能可以压缩
（4）分库分表其实可以在第二步做，但实现较复杂；分表后必然涉及要读取多个表的问题，但对开发是透明的，在应用开发与数据库中间需要研发一个平台，自动hash索引到分表后的表。举个例子，假设有一张600万的表，可以分为两张表，按时间分，时间点A以前的分一张，500万；另一张表100万，后续的都插入到该表